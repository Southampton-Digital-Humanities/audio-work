{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Speech to Text with Whisper\n",
        "\n",
        "This code book allows you to detect the language(s) found in an audio file and transcribe the audio into text, using the Python package Whisper. It was written by [James Baker](https://www.southampton.ac.uk/humanities/about/staff/jwb1n21.page) in October 2022 and is shared under a under a [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/) (excluding data). Full documentation on how to use Whisper can be found on [GitHub](https://github.com/openai/whisper).\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Make sure you're running the notebook in Firefox or Google Chrome (it will run in other browsers, but if there are issues they can often be browser related).\n",
        "3. Run the cells below: that is, hit the play buttons in order, waiting for each to complete (when a tick appears to the left of the code block) before moving onto the next)\n"
      ],
      "metadata": {
        "id": "WSoh-NKoQWhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Install Whisper**"
      ],
      "metadata": {
        "id": "mXyKJUNBRKTj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UOvKM9c4IXbp"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper"
      ],
      "metadata": {
        "id": "jVT_ThsmIgl5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Load a Whisper model**\n",
        "\n",
        "The smallest is `tiny` the largest is `large`. Replace `small` with your chosen model to change models. Lrger models will take longer to process your audio, but will do so more accurately. Model descriptions can be found [on GitHub](https://github.com/openai/whisper#available-models-and-languages)."
      ],
      "metadata": {
        "id": "O59jDllKRTGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"small\")"
      ],
      "metadata": {
        "id": "QFIh69J_Ij0f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Upload your audio file**\n",
        "\n",
        "Choose ONE of the options below."
      ],
      "metadata": {
        "id": "FRPfXRCtR3CF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Option 1: direct upload*\n",
        "\n",
        "Our example audio file is **the speaking voice of [Anne-Marie Imafidon](https://commons.wikimedia.org/wiki/File:Anne-Marie_Imafidon_voice_-_en.flac)** converted to mp3, [downloadable here](https://drive.google.com/file/d/1ulVCJEJPp77UNJmdSF9IE3Yb7it4yTy1/view?usp=sharing).\n",
        "\n",
        "Once downloaded, in the sidebar on the left of the screen, select *Files* (the folder icon), hit the upload icon, and upload your mp3 to your notebook. Once the file appears in the sidebar you are ready to go."
      ],
      "metadata": {
        "id": "MTJ8FEYeXmuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = whisper.load_audio(\"Anne-Marie_Imafidon_voice_en.mp3\")"
      ],
      "metadata": {
        "id": "6RZxgwPpMNGY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Option 2: mount via Google Drive*\n",
        "\n",
        "This option is ideal for larger files.\n",
        "\n",
        "First, add the audio file to a folder on your Google Drive called `voice-audio`.\n",
        "\n",
        "Second, run this cell below to mount your personal Google Drive in the VM (a prompt may ask for an auth code; that auth is not saved anywhere; after entering you auth code, hit enter)."
      ],
      "metadata": {
        "id": "iarOy6rgXwXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDv-RAjOVGXd",
        "outputId": "e6ea5864-be85-45b3-d456-5d917456ca34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Third, load in the audio file. In this case, the larger `.flac` version of the speaking voice of [Anne-Marie Imafidon](https://commons.wikimedia.org/wiki/File:Anne-Marie_Imafidon_voice_-_en.flac). "
      ],
      "metadata": {
        "id": "T3iEe20uYZrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input=whisper.load_audio(\"/content/drive/MyDrive/voice-audio/Anne-Marie_Imafidon_voice_en.flac\")"
      ],
      "metadata": {
        "id": "soKjV8iKVdj5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. This code block detects the language of the audio file**"
      ],
      "metadata": {
        "id": "omhc9bkUQBgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load audio and pad/trim it to fit 30 seconds\n",
        "audio = whisper.pad_or_trim(input)\n",
        "\n",
        "# make log-Mel spectrogram and move to the same device as the model\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "# detect the spoken language\n",
        "_, probs = model.detect_language(mel)\n",
        "print(f\"Detected language: {max(probs, key=probs.get)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ8As51AMKYO",
        "outputId": "890b28d6-c165-4864-be30-68161eb9dac9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Transcribe the audio file**"
      ],
      "metadata": {
        "id": "l5HOOKvFTg1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8MPBOlgJ_jQ",
        "outputId": "a7100536-24cd-4fbd-f65e-08aca625a1dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Print the output**"
      ],
      "metadata": {
        "id": "TD0kjFXETkoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXYMLy_MKRHt",
        "outputId": "f8759e44-7134-4e95-d37f-9cc08eea543a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hello, I'm Anne-Marie Imaffidon. I was born in Barking Essex and I now run social enterprise, Stemets. I also love Nando's.\n"
          ]
        }
      ]
    }
  ]
}